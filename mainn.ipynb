{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1df69ec",
   "metadata": {},
   "source": [
    "# Load and exploration of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b38f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "              id                                               text  \\\n",
      "0   500796286320  Wow! From what I've observed from this documen...   \n",
      "1   838906157157  काय रे dungnat मेंदु असणाऱ्या आंधभक्ता तुझा आई...   \n",
      "2  1011026626743  अजित दादा आणि प्रफुल्ल पटेल यांनी केलेल्या काम...   \n",
      "3  1068853499446  She's saying that \"doing her own research\" led...   \n",
      "4   502772748919  That is not Karen, that is perfectly reasonabl...   \n",
      "\n",
      "   complaint  demands  praise  questions  \n",
      "0        0.0      0.0     1.0        0.0  \n",
      "1        1.0      0.0     0.0        0.0  \n",
      "2        0.0      0.0     1.0        0.0  \n",
      "3        1.0      0.0     0.0        0.0  \n",
      "4        1.0      0.0     0.0        0.0  \n",
      "\n",
      "Test data:\n",
      "              id                                               text\n",
      "0  1041016773991  मोदी साहेब वरती चांगले तो पण त्यांच्या साईटला ...\n",
      "1   109362481297  In #Jawan you will get: 1. 1st class action 2....\n",
      "2   985019053532  किती दहशत आहे दोन्ही पवारांची बारामती कर मोकळे...\n",
      "3   436629695381  आजवर का नाही विकास केलात मित्रा घरात किती प्रत...\n",
      "4   585196067684  घराणेशाही थांबवायची असेल तर मोठ्या कॉलेज विद्य...\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Display the first few rows of each dataset to understand their structure\n",
    "print(\"Training data:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(test_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1c658",
   "metadata": {},
   "source": [
    "# Preprocessing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5a8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.strip()  # Remove leading/trailing whitespace\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "train_df['text'] = train_df['text'].apply(clean_text)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "X = tokenizer.texts_to_sequences(train_df['text'])\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "\n",
    "# Labels\n",
    "y = train_df[['complaint', 'demands', 'praise', 'questions']].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a8d1e",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad33948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dense(4, activation='sigmoid')  # 4 outputs for multi-label classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63301c",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30db761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.4069 - loss: 0.5471 - val_accuracy: 0.4712 - val_loss: 0.5070\n",
      "Epoch 2/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.4353 - loss: 0.5048 - val_accuracy: 0.4550 - val_loss: 0.5067\n",
      "Epoch 3/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - accuracy: 0.4436 - loss: 0.4993 - val_accuracy: 0.4487 - val_loss: 0.5069\n",
      "Epoch 4/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - accuracy: 0.5179 - loss: 0.4653 - val_accuracy: 0.4850 - val_loss: 0.5011\n",
      "Epoch 5/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6143 - loss: 0.3803 - val_accuracy: 0.4737 - val_loss: 0.5444\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59569319",
   "metadata": {},
   "source": [
    "# Evaluating the modeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14b305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4757 - loss: 0.5446\n",
      "Validation Loss: 0.5443693399429321, Validation Accuracy: 0.4737499952316284\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b28cd",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57cfd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the test data\n",
    "test_df['text'] = test_df['text'].apply(clean_text)\n",
    "X_test = tokenizer.texts_to_sequences(test_df['text'])\n",
    "X_test = pad_sequences(X_test, maxlen=100)\n",
    "\n",
    "# Predict probabilities\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame(predictions, columns=['complaint', 'demands', 'praise', 'questions'])\n",
    "submission.insert(0, 'id', test_df['id'])\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689f872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
